---
title: 文本表示
date: 2019-11-12 14:20:09
tags: nlp
---

## 词袋模型
### 概念介绍
引用Wikipedia的介绍
> 词袋模型（英语：Bag-of-words model）是个在自然语言处理和信息检索(IR)下被简化的表达模型。此模型下，一段文本（比如一个句子或是一个文档）可以用一个装着这些词的袋子来表示，这种表示方式不考虑文法以及词的顺序。
 
### 计算方法
对于两个句子
```
s1 = John likes to watch movies. Mary likes movies too.
s2 = John also likes to watch football games.
```
首先统计出两个句子中的词的集合，即词典(vocabulary)：
```
[‘also’, ‘football’, ‘games’, ‘john’, ‘likes’, ‘mary’, ‘movies’, ‘to’, ‘too’, ‘watch’]
```
每个句子的词袋模型向量的维度就是词典中词的个数，每个维度的值是按照词典的词的顺序，计算词典中的词在句子中出现的次数。这个例子中，每个句子用10维的向量表示，第一个词是also，在第一个句子中出现的次数是0，所以第一维是0，词典中第5个词likes在第一个句子中出现的次数是2，第五维是2。由此得到两个句子的向量表示
```
s1 = [0 0 0 1 2 1 2 1 1 1]
s2 = [1 1 1 1 1 0 0 1 0 1]
```
可以使用scikit-learn计算词袋模型表示
```
corpus = [
    "John likes to watch movies, Mary likes movies too",
    "John also likes to watch football games",
]
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(corpus)
print('vacubulary: ', vectorizer.get_feature_names())
print(X.toarray())

# output:
# vacubulary:  ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch']
# [[0 0 0 1 2 1 2 1 1 1]
#  [1 1 1 1 1 0 0 1 0 1]]
```
## TF-IDF
### 概念介绍
> tf-idf（英语：term frequency–inverse document frequency）是一种用于信息检索与文本挖掘的常用加权技术。tf-idf是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。tf-idf加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了tf-idf以外，互联网上的搜索引擎还会使用基于链接分析的评级方法，以确定文件在搜索结果中出现的顺序。

脱俗一点理解就是一个词如果在一个文档中出现的频次越多说明越重要，但这个词可能在整个语料库中也很常见，所以这个词要能体现这个文档的特征，不仅要在当前文档中出现频次多，还要在语料库中的其他文档里出现的频次少。

### 计算方法
tf-idf值由两部分组成：词频（term frequency，tf）和逆向文件频率（inverse document frequency，idf）

tf值是一个词在当前文档中出现的频次，词$w_i$的词频是:
$$
{\displaystyle \mathrm {tf_{i,j}} ={\frac {n_{i,j}}{\sum _{k}n_{k,j}}}}
$$
分子${\displaystyle n_{i,j}}$表示词$w_i$在文档${\displaystyle d_{j}}$中的出现次数，分母表示文档${\displaystyle d_{j}}$中每次词出现的次数之和，即该文档的总词数。
逆向文件频率（inverse document frequency，idf）是一个词语普遍重要性的度量。某一特定词语的idf，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取以10为底的对数得到：
$$
{\displaystyle \mathrm {idf_{i}} =\lg {\frac {|D|}{|\{j:t_{i}\in d_{j}\}| + 1}}}
$$
分子$|D|$表示语料库中的文档总数，分母比表示包含词$w_i$的文档的个数，为了防止分母为0，给这个值加1。
tf-idf值为：
$$
{tfidf_{i,j} =\mathrm {tf_{i,j}} \times \mathrm {idf_{i}} }
$$